{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "- Collaborative Filtering을 샘플 데이터셋으로, 실습해보며 코드를 짜봅니다.\n",
    "- data: MovieLens dataset ([Movielens Dataset]( https://grouplens.org/datasets/movielens/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/ml-latest-small/ratings.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77701</th>\n",
       "      <td>483</td>\n",
       "      <td>8529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1215545278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94477</th>\n",
       "      <td>599</td>\n",
       "      <td>33437</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1498518389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36246</th>\n",
       "      <td>247</td>\n",
       "      <td>5349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1467645405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>111</td>\n",
       "      <td>7361</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1516140853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300</th>\n",
       "      <td>610</td>\n",
       "      <td>57504</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1493847901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "77701      483     8529     4.0  1215545278\n",
       "94477      599    33437     2.5  1498518389\n",
       "36246      247     5349     2.0  1467645405\n",
       "17483      111     7361     3.5  1516140853\n",
       "100300     610    57504     4.5  1493847901"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=0)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- userId 와 movieId 는 각각 카테고리컬 변수이다. 이를 각각 인코딩 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 483\n"
     ]
    }
   ],
   "source": [
    "for name, index in enumerate(train_set['userId'].unique()):\n",
    "    print(name, index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_to_index(column, train_column=None):\n",
    "    if train_column is not None:\n",
    "        unique = train_column.unique()\n",
    "    else:\n",
    "        unique = column.unique()\n",
    "    id_to_index = {id_: index for index, id_ in enumerate(unique)}\n",
    "    return id_to_index, np.array([id_to_index.get(id_, -1) for id_ in column]), len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df, train=None):\n",
    "    df = df.copy()\n",
    "    for col_name in [\"userId\", \"movieId\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _, col, _ = column_to_index(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >=0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating   timestamp\n",
      "77701      483     8529     4.0  1215545278\n",
      "94477      599    33437     2.5  1498518389\n",
      "36246      247     5349     2.0  1467645405\n",
      "17483      111     7361     3.5  1516140853\n",
      "100300     610    57504     4.5  1493847901\n",
      "       userId  movieId  rating   timestamp\n",
      "41008     276      780     5.0   858350384\n",
      "94274     599     7624     2.5  1519235950\n",
      "77380     483     1320     2.5  1215895327\n",
      "29744     202     3448     3.0   974924072\n",
      "40462     274    60291     4.0  1296947017\n"
     ]
    }
   ],
   "source": [
    "# encode 전 train dataset, test dataset\n",
    "print(train_set.head())\n",
    "print(test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating   timestamp\n",
      "77701        0        0     4.0  1215545278\n",
      "94477        1        1     2.5  1498518389\n",
      "36246        2        2     2.0  1467645405\n",
      "17483        3        3     3.5  1516140853\n",
      "100300       4        4     4.5  1493847901\n",
      "       userId  movieId  rating   timestamp\n",
      "41008     119      135     5.0   858350384\n",
      "94274       1     7243     2.5  1519235950\n",
      "77380       0     1830     2.5  1215895327\n",
      "29744      35     1666     3.0   974924072\n",
      "40462     105     8418     4.0  1296947017\n"
     ]
    }
   ],
   "source": [
    "# encoding 후 train dataset, test datasett\n",
    "train_set_encoded = encode_data(train_set)\n",
    "test_set_encoded = encode_data(test_set, train_set)\n",
    "print(train_set_encoded.head())\n",
    "print(test_set_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization Model using Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=100):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user = self.user_embedding(user)\n",
    "        item = self.item_embedding(item)\n",
    "        return (user * item).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 8975\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train_set_encoded['userId'].unique())\n",
    "num_items = len(train_set_encoded['movieId'].unique())\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model = MatrixFactorization(num_users, num_items, embedding_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        users = torch.LongTensor(train_set_encoded['userId'].values)\n",
    "        items = torch.LongTensor(train_set_encoded['movieId'].values)\n",
    "        ratings = torch.FloatTensor(train_set['rating'].values)\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "    test_loss(model, unsqueeze)\n",
    "    \n",
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(test_set_encoded['userId'].values)\n",
    "    items = torch.LongTensor(test_set_encoded['movieId'].values)\n",
    "    ratings = torch.FloatTensor(test_set_encoded['rating'].values)\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    print(\"test loss: {0:.3f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.70184326171875\n",
      "63.00698471069336\n",
      "35.89173126220703\n",
      "21.98044204711914\n",
      "14.95960521697998\n",
      "11.285816192626953\n",
      "9.227702140808105\n",
      "7.960115909576416\n",
      "7.062285900115967\n",
      "6.309814929962158\n",
      "test loss: 46.518\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.602383136749268\n",
      "2.82804799079895\n",
      "1.669775128364563\n",
      "1.1921473741531372\n",
      "0.9990464448928833\n",
      "0.9065325260162354\n",
      "0.8331282138824463\n",
      "0.7519912719726562\n",
      "0.6618367433547974\n",
      "0.5699629783630371\n",
      "test loss: 31.496\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48468807339668274\n",
      "0.5511645078659058\n",
      "0.2787975072860718\n",
      "0.2851133644580841\n",
      "0.2790704071521759\n",
      "0.213246151804924\n",
      "0.16214504837989807\n",
      "0.14261886477470398\n",
      "0.13167637586593628\n",
      "0.11433210968971252\n",
      "0.09560929238796234\n",
      "0.08301843702793121\n",
      "0.07671365141868591\n",
      "0.07192128151655197\n",
      "0.06493764370679855\n",
      "test loss: 25.210\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=15, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05660627782344818\n",
      "0.0290948785841465\n",
      "0.02249792590737343\n",
      "0.02166203036904335\n",
      "0.019849905744194984\n",
      "0.017429808154702187\n",
      "0.01568765938282013\n",
      "0.0146896131336689\n",
      "0.013876928947865963\n",
      "0.012871747836470604\n",
      "0.011670161038637161\n",
      "0.01047046110033989\n",
      "0.00944160670042038\n",
      "0.00861365720629692\n",
      "0.007955825887620449\n",
      "test loss: 24.924\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007437265943735838\n",
      "0.021590830758213997\n",
      "0.010936557315289974\n",
      "0.011654525063931942\n",
      "0.0112707344815135\n",
      "0.008976185694336891\n",
      "0.00746501050889492\n",
      "0.007118956185877323\n",
      "0.006899690721184015\n",
      "0.006358754821121693\n",
      "test loss: 24.912\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Matrix Initialize with uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization_uniform(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=100):\n",
    "        super(MatrixFactorization_uniform, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        self.user_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.item_embedding.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user = self.user_embedding(user)\n",
    "        item = self.item_embedding(item)\n",
    "        return (user * item).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_uniform_model = MatrixFactorization_uniform(num_users, num_items, embedding_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.918964385986328\n",
      "4.932332515716553\n",
      "2.4280447959899902\n",
      "3.2279775142669678\n",
      "0.8523130416870117\n",
      "1.782036304473877\n",
      "2.661961078643799\n",
      "2.167083263397217\n",
      "1.0884267091751099\n",
      "0.9171753525733948\n",
      "test loss: 1.930\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.642383098602295\n",
      "1.4289661645889282\n",
      "1.7477048635482788\n",
      "1.0553420782089233\n",
      "0.7338014841079712\n",
      "1.0947291851043701\n",
      "1.1368614435195923\n",
      "0.7798032164573669\n",
      "0.6455827355384827\n",
      "0.8126983642578125\n",
      "test loss: 1.151\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9467490315437317\n",
      "2.5234551429748535\n",
      "0.7070660591125488\n",
      "0.9120100736618042\n",
      "1.5028444528579712\n",
      "1.397505760192871\n",
      "0.9052100777626038\n",
      "0.6227729320526123\n",
      "0.796795129776001\n",
      "0.998343825340271\n",
      "0.865805983543396\n",
      "0.6432095170021057\n",
      "0.6104221343994141\n",
      "0.7122362852096558\n",
      "0.7603340744972229\n",
      "test loss: 1.002\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=15, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6835158467292786\n",
      "0.5082820057868958\n",
      "0.5317350625991821\n",
      "0.5594138503074646\n",
      "0.5279513597488403\n",
      "0.48834744095802307\n",
      "0.4747507572174072\n",
      "0.4818984568119049\n",
      "0.4867956340312958\n",
      "0.47664275765419006\n",
      "0.4556306004524231\n",
      "0.43555617332458496\n",
      "0.424803227186203\n",
      "0.4224257171154022\n",
      "0.420448899269104\n",
      "test loss: 0.809\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4121911823749542\n",
      "0.4401232898235321\n",
      "0.39664122462272644\n",
      "0.37656882405281067\n",
      "0.38303276896476746\n",
      "0.36874154210090637\n",
      "0.34401237964630127\n",
      "0.3308502435684204\n",
      "0.3265977203845978\n",
      "0.31687480211257935\n",
      "test loss: 0.811\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=10, lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
