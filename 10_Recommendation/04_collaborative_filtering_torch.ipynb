{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "- Collaborative Filtering을 샘플 데이터셋으로, 실습해보며 코드를 짜봅니다.\n",
    "- data: MovieLens dataset ([Movielens Dataset]( https://grouplens.org/datasets/movielens/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./data/ml-latest-small/ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./data/ml-latest-small/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77701</th>\n",
       "      <td>483</td>\n",
       "      <td>8529</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1215545278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94477</th>\n",
       "      <td>599</td>\n",
       "      <td>33437</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1498518389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36246</th>\n",
       "      <td>247</td>\n",
       "      <td>5349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1467645405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17483</th>\n",
       "      <td>111</td>\n",
       "      <td>7361</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1516140853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300</th>\n",
       "      <td>610</td>\n",
       "      <td>57504</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1493847901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "77701      483     8529     4.0  1215545278\n",
       "94477      599    33437     2.5  1498518389\n",
       "36246      247     5349     2.0  1467645405\n",
       "17483      111     7361     3.5  1516140853\n",
       "100300     610    57504     4.5  1493847901"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(ratings, test_size=0.2, random_state=0)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- userId 와 movieId 는 각각 카테고리컬 변수이다. 이를 각각 인코딩 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_to_index(column, train_column=None):\n",
    "    if train_column is not None:\n",
    "        unique = train_column.unique()\n",
    "    else:\n",
    "        unique = column.unique()\n",
    "    id_to_index = {id_: index for index, id_ in enumerate(unique)}\n",
    "    return id_to_index, np.array([id_to_index.get(id_, -1) for id_ in column]), len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df, train=None):\n",
    "    df = df.copy()\n",
    "    for col_name in [\"userId\", \"movieId\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _, col, _ = column_to_index(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >=0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating   timestamp\n",
      "77701      483     8529     4.0  1215545278\n",
      "94477      599    33437     2.5  1498518389\n",
      "36246      247     5349     2.0  1467645405\n",
      "17483      111     7361     3.5  1516140853\n",
      "100300     610    57504     4.5  1493847901\n",
      "       userId  movieId  rating   timestamp\n",
      "41008     276      780     5.0   858350384\n",
      "94274     599     7624     2.5  1519235950\n",
      "77380     483     1320     2.5  1215895327\n",
      "29744     202     3448     3.0   974924072\n",
      "40462     274    60291     4.0  1296947017\n"
     ]
    }
   ],
   "source": [
    "# encode 전 train dataset, test dataset\n",
    "print(train_set.head())\n",
    "print(test_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  movieId  rating   timestamp\n",
      "77701        0        0     4.0  1215545278\n",
      "94477        1        1     2.5  1498518389\n",
      "36246        2        2     2.0  1467645405\n",
      "17483        3        3     3.5  1516140853\n",
      "100300       4        4     4.5  1493847901\n",
      "       userId  movieId  rating   timestamp\n",
      "41008     119      135     5.0   858350384\n",
      "94274       1     7243     2.5  1519235950\n",
      "77380       0     1830     2.5  1215895327\n",
      "29744      35     1666     3.0   974924072\n",
      "40462     105     8418     4.0  1296947017\n"
     ]
    }
   ],
   "source": [
    "# encoding 후 train dataset, test datasett\n",
    "train_set_encoded = encode_data(train_set)\n",
    "test_set_encoded = encode_data(test_set, train_set)\n",
    "print(train_set_encoded.head())\n",
    "print(test_set_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Batch Iterator\n",
    "- Batch 별로 Iterate 해주기 위한, Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DataIterator:\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    \n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        \n",
    "        return self.X[k*bs:(k+1)*bs], self.y[k*bs:(k+1)*bs]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in DataIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization Model using Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=100):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user = self.user_embedding(user)\n",
    "        item = self.item_embedding(item)\n",
    "        return (user * item).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 8975\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train_set_encoded['userId'].unique())\n",
    "num_items = len(train_set_encoded['movieId'].unique())\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model = MatrixFactorization(num_users, num_items, embedding_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        users = torch.LongTensor(train_set_encoded['userId'].values)\n",
    "        items = torch.LongTensor(train_set_encoded['movieId'].values)\n",
    "        ratings = torch.FloatTensor(train_set['rating'].values)\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "    test_loss(model, unsqueeze)\n",
    "    \n",
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(test_set_encoded['userId'].values)\n",
    "    items = torch.LongTensor(test_set_encoded['movieId'].values)\n",
    "    ratings = torch.FloatTensor(test_set_encoded['rating'].values)\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    print(\"test loss: {0:.3f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.4322738647461\n",
      "63.018524169921875\n",
      "35.95763397216797\n",
      "22.013687133789062\n",
      "14.920804023742676\n",
      "11.190710067749023\n",
      "9.11557674407959\n",
      "7.861675262451172\n",
      "6.988626956939697\n",
      "6.261568546295166\n",
      "test loss: 46.418\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.580074787139893\n",
      "2.839423894882202\n",
      "1.6660510301589966\n",
      "1.1793171167373657\n",
      "0.9820349216461182\n",
      "0.8887496590614319\n",
      "0.8185961842536926\n",
      "0.7408943772315979\n",
      "0.652494490146637\n",
      "0.5622036457061768\n",
      "test loss: 31.243\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4794389605522156\n",
      "0.5453332662582397\n",
      "0.27274689078330994\n",
      "0.2827778160572052\n",
      "0.2757742404937744\n",
      "0.20973117649555206\n",
      "0.15962329506874084\n",
      "0.1408979892730713\n",
      "0.1299412101507187\n",
      "0.11288973689079285\n",
      "0.09474336355924606\n",
      "0.0820499062538147\n",
      "0.07524076849222183\n",
      "0.0701921358704567\n",
      "0.0635247603058815\n",
      "test loss: 25.021\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=15, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055700261145830154\n",
      "0.0283324234187603\n",
      "0.021986456587910652\n",
      "0.021038152277469635\n",
      "0.019089234992861748\n",
      "0.01672755554318428\n",
      "0.015100487507879734\n",
      "0.014193456619977951\n",
      "0.013453289866447449\n",
      "0.0124736949801445\n",
      "0.011277560144662857\n",
      "0.010084757581353188\n",
      "0.009070792235434055\n",
      "0.008271683938801289\n",
      "0.007653325330466032\n",
      "test loss: 24.786\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007174388971179724\n",
      "0.02144342102110386\n",
      "0.010863028466701508\n",
      "0.011516516096889973\n",
      "0.011108600534498692\n",
      "0.008899148553609848\n",
      "0.007382851094007492\n",
      "0.007020988501608372\n",
      "0.006790283601731062\n",
      "0.006282983813434839\n",
      "test loss: 24.782\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_model, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Matrix Initialize with uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization_uniform(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=100):\n",
    "        super(MatrixFactorization_uniform, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        self.user_embedding.weight.data.uniform_(0, 0.05)\n",
    "        self.item_embedding.weight.data.uniform_(0, 0.05)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user = self.user_embedding(user)\n",
    "        item = self.item_embedding(item)\n",
    "        return (user * item).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_uniform_model = MatrixFactorization_uniform(num_users, num_items, embedding_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.919435501098633\n",
      "4.933681488037109\n",
      "2.4307403564453125\n",
      "3.229398250579834\n",
      "0.8534629344940186\n",
      "1.7833770513534546\n",
      "2.6639256477355957\n",
      "2.1696536540985107\n",
      "1.0906656980514526\n",
      "0.9177945256233215\n",
      "test loss: 1.928\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6422327756881714\n",
      "1.4307241439819336\n",
      "1.74745774269104\n",
      "1.054850459098816\n",
      "0.73503577709198\n",
      "1.0960299968719482\n",
      "1.137143850326538\n",
      "0.7800192832946777\n",
      "0.6460190415382385\n",
      "0.8131081461906433\n",
      "test loss: 1.150\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9471482634544373\n",
      "2.5225729942321777\n",
      "0.7070363163948059\n",
      "0.9123658537864685\n",
      "1.502804160118103\n",
      "1.3970897197723389\n",
      "0.9053442478179932\n",
      "0.6238166689872742\n",
      "0.7975934147834778\n",
      "0.9980548024177551\n",
      "0.8657450079917908\n",
      "0.6443963646888733\n",
      "0.6120921969413757\n",
      "0.7133476734161377\n",
      "0.7606694102287292\n",
      "test loss: 1.000\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=15, lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683856189250946\n",
      "0.5094601511955261\n",
      "0.5330264568328857\n",
      "0.5602948069572449\n",
      "0.5288777351379395\n",
      "0.48965221643447876\n",
      "0.47636333107948303\n",
      "0.4834703803062439\n",
      "0.48810875415802\n",
      "0.47780880331993103\n",
      "0.45691660046577454\n",
      "0.4371405243873596\n",
      "0.4266369938850403\n",
      "0.42426589131355286\n",
      "0.42207497358322144\n",
      "test loss: 0.809\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41360846161842346\n",
      "0.4417349696159363\n",
      "0.39798808097839355\n",
      "0.3782435953617096\n",
      "0.38461095094680786\n",
      "0.3701026737689972\n",
      "0.34544897079467773\n",
      "0.3323555588722229\n",
      "0.3279605507850647\n",
      "0.3180648386478424\n",
      "test loss: 0.809\n"
     ]
    }
   ],
   "source": [
    "train_model(mf_uniform_model, epochs=10, lr=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
