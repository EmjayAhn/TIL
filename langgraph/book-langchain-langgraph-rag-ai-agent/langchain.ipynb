{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc34ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 이름은 안민재입니다! 😊\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "model = AzureChatOpenAI(model=\"gpt-4o\",\n",
    "                        api_version=\"2025-04-01-preview\",\n",
    "                        temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"안녕하세요. 제 이름은 안민재입니다.\"),\n",
    "    AIMessage(\"안녕하세요. 안민재님. 반가워요.\"),\n",
    "    HumanMessage(\"제 이름이 뭐에요?\")\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4084f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 😊 어떻게 도와드릴까요?"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"안녕!\"),\n",
    "]\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f08400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      다음 요리의 레시피를 생각해주세요.\n",
      "                                      요리명: 카레\n",
      "                                      \n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "                                      다음 요리의 레시피를 생각해주세요.\n",
    "                                      요리명: {dish}\n",
    "                                      \"\"\")\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"카레\"})\n",
    "print(prompt_value.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='사용자가 입력한 요리의 레시피를 생각해 주세요.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='카레', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='카레 레시피', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"사용자가 입력한 요리의 레시피를 생각해 주세요.\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "        (\"ai\", \"{recipe}\"), #(\"assistant\", \"\") 도 가능\n",
    "    ]\n",
    ")\n",
    "prompt_value = prompt.invoke({\"dish\": \"카레\", \"recipe\": \"카레 레시피\"})\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24eb9261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='안녕하세요, 저는 안민재입니다.!', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='안녕하세요, 안민재님. 반가워요.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='제 이름이 뭐에요?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Messages Placeholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"안녕하세요, 저는 안민재입니다.!\"),\n",
    "            AIMessage(content=\"안녕하세요, 안민재님. 반가워요.\"),\n",
    "        ],\n",
    "        \"input\": \"제 이름이 뭐에요?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c148a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 이름은 안민재입니다! 😊\n"
     ]
    }
   ],
   "source": [
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5fdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Output Parsers\n",
    "# PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c835fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
