{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc34ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "model = AzureChatOpenAI(model=\"gpt-4o\",\n",
    "                        api_version=\"2025-04-01-preview\",\n",
    "                        temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"안녕하세요. 제 이름은 안민재입니다.\"),\n",
    "    AIMessage(\"안녕하세요. 안민재님. 반가워요.\"),\n",
    "    HumanMessage(\"제 이름이 뭐에요?\")\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4084f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"안녕!\"),\n",
    "]\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f08400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "                                      다음 요리의 레시피를 생각해주세요.\n",
    "                                      요리명: {dish}\n",
    "                                      \"\"\")\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"카레\"})\n",
    "print(prompt_value.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"사용자가 입력한 요리의 레시피를 생각해 주세요.\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "        (\"ai\", \"{recipe}\"), #(\"assistant\", \"\") 도 가능\n",
    "    ]\n",
    ")\n",
    "prompt_value = prompt.invoke({\"dish\": \"카레\", \"recipe\": \"카레 레시피\"})\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messages Placeholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"안녕하세요, 저는 안민재입니다.!\"),\n",
    "            AIMessage(content=\"안녕하세요, 안민재님. 반가워요.\"),\n",
    "        ],\n",
    "        \"input\": \"제 이름이 뭐에요?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c148a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5fdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Parsers\n",
    "# PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c835fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"사용자가 입력한 요리의 레시피를 생각해 주세요. \\n\\n\"\n",
    "         \"{format_instructions}\"\n",
    "         ),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_with_format_instructions = prompt.partial(\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "prompt_value = prompt_with_format_instructions.invoke({\"dish\": \"카레\"})\n",
    "\n",
    "print(\"=== role: system ===\")\n",
    "print(prompt_value.messages[0].content)\n",
    "print(\"=== role: user ===\")\n",
    "print(prompt_value.messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05495c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = output_parser.invoke(ai_message)\n",
    "print(type(recipe))\n",
    "print(recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "ai_message = AIMessage(content=\"안녕하세요, 저는 AI 어시턴트입니다.\")\n",
    "ai_message = output_parser.invoke(ai_message)\n",
    "print(type(ai_message))\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa3cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL (LangChain Expression Language)\n",
    "# 연쇄적으로 연결하고 싶은 경우\n",
    "# Prompt template 을 채우고, 그 결과를 Chat model에 제공한 후 그 결과를 Python 객체로 변환\n",
    "\n",
    "# prompt와 model 연결\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"사용자가 입력한 요리의 레시피를 생각해 주세요.\"),\n",
    "        (\"human\", \"{dish}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "ai_message = chain.invoke({\"dish\": \"카레\"})\n",
    "print(ai_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrOutputParser를 연결에 추가\n",
    "# prompt, model, StrOutputParser 연결은 LCE의 가장 기본적인 형태\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "output = chain.invoke({\"dish\": \"카레\"})\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic Output Parser를 사용한 연결\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(descriptions=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(descriptions=\"steps to make the dish\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "propmt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"사용자가 입력한 요리의 레시피를 생각해 주세요. \\n\\n {format_instructions}\"\n",
    "        ),\n",
    "        (\"human\", \"{dish}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_with_format_instructions = prompt.partial(\n",
    "    format_instructions=output_parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = prompt_with_format_instructions | model | output_parser\n",
    "\n",
    "recipe = chain.invoke({\"dish\": \"카레\"})\n",
    "print(type(recipe))\n",
    "print(recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_structured_output\n",
    "# with_structured_output은 기본적으로 Function calling을 사용하여 json 형식의 데이터를 출력\n",
    "# Function calling은 실제로 함수를 호출하지 않고, json 형식의 데이터를 확실하게 출력하는 목적으로 자주 사용\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"사용자가 입력한 요리의 레시피를 생각해 주세요.\"),\n",
    "        (\"human\", \"{dish}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = prompt | model.with_structured_output(Recipe)\n",
    "\n",
    "recipe = chain.invoke({\"dish\": \"카레\"})\n",
    "print(type(recipe))\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57673106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG: 검색증강이라고 단순히 생각하는 것이 아니라 프롬프트에 문맥을 추가하는 방법을 고려\n",
    "# Langchain - RAG component\n",
    "# - Document loader\n",
    "# - Document transformer\n",
    "# - Embedding model\n",
    "# - Vector store\n",
    "# - Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78981d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "raw_docs = loader.load()\n",
    "print(len(raw_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain에서 문서를 청크화 하는 기능군을 \"Text Splitter\"라고 부름\n",
    "# pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자 수로 청크 분할\n",
    "# tiktoken 토큰 수로 분할, python 소스 코드를 가능한 한 클래스나 함수로 분할하는 기능도 있\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "docs = text_splitter.split_documents(raw_docs)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(docs))\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb681bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Model\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    ")\n",
    "\n",
    "embeddings.embed_query(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store : chroma 사용\n",
    "# pip install langchain-chroma\n",
    "# Vector DB 에는 Faiss, Elasticsearch, Redis, Milvus 등 다양한 옵션이 있음\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b71d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever 내부에서 제공된 query를 벡터화해 vector store에 저장된 문서 중에서 벡터 거리가 가장 가까운 것을 찾음\n",
    "\n",
    "query = \"AWS의 S3에서 데이터를 읽어 들이기 위한 Document loader가 있나요?\"\n",
    "\n",
    "context_docs = retriever.invoke(query)\n",
    "print(f\"len = {len(context_docs)}\")\n",
    "\n",
    "first_doc = context_docs[0]\n",
    "print(f\"metadata = {first_doc.metadata}\")\n",
    "print(first_doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
