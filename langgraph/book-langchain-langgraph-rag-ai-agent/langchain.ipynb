{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc34ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "model = AzureChatOpenAI(model=\"gpt-4o\",\n",
    "                        api_version=\"2025-04-01-preview\",\n",
    "                        temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"ì•ˆë…•í•˜ì„¸ìš”. ì œ ì´ë¦„ì€ ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤.\"),\n",
    "    AIMessage(\"ì•ˆë…•í•˜ì„¸ìš”. ì•ˆë¯¼ì¬ë‹˜. ë°˜ê°€ì›Œìš”.\"),\n",
    "    HumanMessage(\"ì œ ì´ë¦„ì´ ë­ì—ìš”?\")\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4084f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"ì•ˆë…•!\"),\n",
    "]\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f08400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ì£¼ì„¸ìš”.\n",
      "                                      ìš”ë¦¬ëª…: ì¹´ë ˆ\n",
      "                                      \n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "                                      ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ì£¼ì„¸ìš”.\n",
    "                                      ìš”ë¦¬ëª…: {dish}\n",
    "                                      \"\"\")\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"ì¹´ë ˆ\"})\n",
    "print(prompt_value.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ì¹´ë ˆ', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='ì¹´ë ˆ ë ˆì‹œí”¼', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "        (\"ai\", \"{recipe}\"), #(\"assistant\", \"\") ë„ ê°€ëŠ¥\n",
    "    ]\n",
    ")\n",
    "prompt_value = prompt.invoke({\"dish\": \"ì¹´ë ˆ\", \"recipe\": \"ì¹´ë ˆ ë ˆì‹œí”¼\"})\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24eb9261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤.!', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì•ˆë¯¼ì¬ë‹˜. ë°˜ê°€ì›Œìš”.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ì œ ì´ë¦„ì´ ë­ì—ìš”?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Messages Placeholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤.!\"),\n",
    "            AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”, ì•ˆë¯¼ì¬ë‹˜. ë°˜ê°€ì›Œìš”.\"),\n",
    "        ],\n",
    "        \"input\": \"ì œ ì´ë¦„ì´ ë­ì—ìš”?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c148a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5fdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Output Parsers\n",
    "# PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c835fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
