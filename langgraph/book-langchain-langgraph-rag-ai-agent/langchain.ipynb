{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc34ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "model = AzureChatOpenAI(model=\"gpt-4o\",\n",
    "                        api_version=\"2025-04-01-preview\",\n",
    "                        temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"ì•ˆë…•í•˜ì„¸ìš”. ì œ ì´ë¦„ì€ ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤.\"),\n",
    "    AIMessage(\"ì•ˆë…•í•˜ì„¸ìš”. ì•ˆë¯¼ì¬ë‹˜. ë°˜ê°€ì›Œìš”.\"),\n",
    "    HumanMessage(\"ì œ ì´ë¦„ì´ ë­ì—ìš”?\")\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4084f3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant.\"),\n",
    "    HumanMessage(\"ì•ˆë…•!\"),\n",
    "]\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f08400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ì£¼ì„¸ìš”.\n",
      "                                      ìš”ë¦¬ëª…: ì¹´ë ˆ\n",
      "                                      \n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "                                      ë‹¤ìŒ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ì£¼ì„¸ìš”.\n",
    "                                      ìš”ë¦¬ëª…: {dish}\n",
    "                                      \"\"\")\n",
    "\n",
    "prompt_value = prompt.invoke({\"dish\": \"ì¹´ë ˆ\"})\n",
    "print(prompt_value.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52dd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ì¹´ë ˆ', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='ì¹´ë ˆ ë ˆì‹œí”¼', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.\"),\n",
    "        (\"human\", \"{dish}\"),\n",
    "        (\"ai\", \"{recipe}\"), #(\"assistant\", \"\") ë„ ê°€ëŠ¥\n",
    "    ]\n",
    ")\n",
    "prompt_value = prompt.invoke({\"dish\": \"ì¹´ë ˆ\", \"recipe\": \"ì¹´ë ˆ ë ˆì‹œí”¼\"})\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24eb9261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤.!', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì•ˆë¯¼ì¬ë‹˜. ë°˜ê°€ì›Œìš”.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ì œ ì´ë¦„ì´ ë­ì—ìš”?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Messages Placeholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are helpful assistant.\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤.!\"),\n",
    "            AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”, ì•ˆë¯¼ì¬ë‹˜. ë°˜ê°€ì›Œìš”.\"),\n",
    "        ],\n",
    "        \"input\": \"ì œ ì´ë¦„ì´ ë­ì—ìš”?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c148a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì•ˆë¯¼ì¬ì…ë‹ˆë‹¤! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5fdfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Output Parsers\n",
    "# PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
    "    steps: list[str] = Field(description=\"steps to make the dish\")\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c835fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== role: system ===\n",
      "ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”. \n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
      "```\n",
      "=== role: user ===\n",
      "ì¹´ë ˆ\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "         \"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”. \\n\\n\"\n",
    "         \"{format_instructions}\"\n",
    "         ),\n",
    "        (\"human\", \"{dish}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_with_format_instructions = prompt.partial(\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "prompt_value = prompt_with_format_instructions.invoke({\"dish\": \"ì¹´ë ˆ\"})\n",
    "\n",
    "print(\"=== role: system ===\")\n",
    "print(prompt_value.messages[0].content)\n",
    "print(\"=== role: user ===\")\n",
    "print(prompt_value.messages[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c75c70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"ingredients\": [\n",
      "    \"ì¹´ë ˆ ê°€ë£¨\",\n",
      "    \"ê°ì\",\n",
      "    \"ë‹¹ê·¼\",\n",
      "    \"ì–‘íŒŒ\",\n",
      "    \"ê³ ê¸° (ì†Œê³ ê¸° ë˜ëŠ” ë‹­ê³ ê¸°)\",\n",
      "    \"ë¬¼\",\n",
      "    \"ì‹ìš©ìœ \",\n",
      "    \"ì†Œê¸ˆ\",\n",
      "    \"í›„ì¶”\"\n",
      "  ],\n",
      "  \"steps\": [\n",
      "    \"ê°ì, ë‹¹ê·¼, ì–‘íŒŒë¥¼ ë¨¹ê¸° ì¢‹ì€ í¬ê¸°ë¡œ ì¬ë‹¤.\",\n",
      "    \"ê³ ê¸°ë¥¼ ì ë‹¹í•œ í¬ê¸°ë¡œ ì°ê³  ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•œë‹¤.\",\n",
      "    \"ëƒ„ë¹„ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì–‘íŒŒë¥¼ ë³¶ì•„ í–¥ì„ ë‚¸ë‹¤.\",\n",
      "    \"ê³ ê¸°ë¥¼ ë„£ê³  ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.\",\n",
      "    \"ê°ìì™€ ë‹¹ê·¼ì„ ë„£ê³  í•¨ê»˜ ë³¶ëŠ”ë‹¤.\",\n",
      "    \"ë¬¼ì„ ëƒ„ë¹„ì— ë¶“ê³  ë“ì¸ë‹¤.\",\n",
      "    \"ì¬ë£Œê°€ ìµìœ¼ë©´ ì¹´ë ˆ ê°€ë£¨ë¥¼ ë„£ê³  ì˜ ì„ëŠ”ë‹¤.\",\n",
      "    \"ì•½í•œ ë¶ˆì—ì„œ ì¹´ë ˆê°€ ê±¸ì­‰í•´ì§ˆ ë•Œê¹Œì§€ ë“ì¸ë‹¤.\",\n",
      "    \"ì™„ì„±ëœ ì¹´ë ˆë¥¼ ë°¥ê³¼ í•¨ê»˜ ì œê³µí•œë‹¤.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "ai_message = model.invoke(prompt_value)\n",
    "print(ai_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05495c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Recipe'>\n",
      "ingredients=['ì¹´ë ˆ ê°€ë£¨', 'ê°ì', 'ë‹¹ê·¼', 'ì–‘íŒŒ', 'ê³ ê¸° (ì†Œê³ ê¸° ë˜ëŠ” ë‹­ê³ ê¸°)', 'ë¬¼', 'ì‹ìš©ìœ ', 'ì†Œê¸ˆ', 'í›„ì¶”'] steps=['ê°ì, ë‹¹ê·¼, ì–‘íŒŒë¥¼ ë¨¹ê¸° ì¢‹ì€ í¬ê¸°ë¡œ ì¬ë‹¤.', 'ê³ ê¸°ë¥¼ ì ë‹¹í•œ í¬ê¸°ë¡œ ì°ê³  ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„ í•œë‹¤.', 'ëƒ„ë¹„ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì–‘íŒŒë¥¼ ë³¶ì•„ í–¥ì„ ë‚¸ë‹¤.', 'ê³ ê¸°ë¥¼ ë„£ê³  ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.', 'ê°ìì™€ ë‹¹ê·¼ì„ ë„£ê³  í•¨ê»˜ ë³¶ëŠ”ë‹¤.', 'ë¬¼ì„ ëƒ„ë¹„ì— ë¶“ê³  ë“ì¸ë‹¤.', 'ì¬ë£Œê°€ ìµìœ¼ë©´ ì¹´ë ˆ ê°€ë£¨ë¥¼ ë„£ê³  ì˜ ì„ëŠ”ë‹¤.', 'ì•½í•œ ë¶ˆì—ì„œ ì¹´ë ˆê°€ ê±¸ì­‰í•´ì§ˆ ë•Œê¹Œì§€ ë“ì¸ë‹¤.', 'ì™„ì„±ëœ ì¹´ë ˆë¥¼ ë°¥ê³¼ í•¨ê»˜ ì œê³µí•œë‹¤.']\n"
     ]
    }
   ],
   "source": [
    "recipe = output_parser.invoke(ai_message)\n",
    "print(type(recipe))\n",
    "print(recipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e242b184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” AI ì–´ì‹œí„´íŠ¸ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# StrOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "ai_message = AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” AI ì–´ì‹œí„´íŠ¸ì…ë‹ˆë‹¤.\")\n",
    "ai_message = output_parser.invoke(ai_message)\n",
    "print(type(ai_message))\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa3cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¹´ë ˆëŠ” ê°„ë‹¨í•˜ë©´ì„œë„ ë§›ìˆê²Œ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ìš”ë¦¬ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” ê¸°ë³¸ì ì¸ í•œêµ­ì‹ ì¹´ë ˆ ë ˆì‹œí”¼ì…ë‹ˆë‹¤. \n",
      "\n",
      "### ì¬ë£Œ:\n",
      "- **ì¹´ë ˆ ê°€ë£¨**: 1ë´‰ì§€ (ì•½ 100g, ì¸ì›ìˆ˜ì— ë”°ë¼ ì¡°ì ˆ)\n",
      "- **ê³ ê¸°**: ë¼ì§€ê³ ê¸°, ì†Œê³ ê¸°, ë‹­ê³ ê¸° ì¤‘ ì„ íƒ (ì•½ 200~300g)\n",
      "- **ê°ì**: 2~3ê°œ\n",
      "- **ë‹¹ê·¼**: 1ê°œ\n",
      "- **ì–‘íŒŒ**: 1~2ê°œ\n",
      "- **ë¬¼**: ì•½ 800ml (ì¹´ë ˆ ê°€ë£¨ í¬ì¥ì§€ì— ì íŒ ì–‘ì„ ì°¸ê³ )\n",
      "- **ì‹ìš©ìœ **: ì•½ê°„\n",
      "- **ë°¥**: ì ë‹¹ëŸ‰ (ì¹´ë ˆì™€ í•¨ê»˜ ê³ë“¤ì¼ ë°¥)\n",
      "\n",
      "---\n",
      "\n",
      "### ì¡°ë¦¬ ë°©ë²•:\n",
      "\n",
      "1. **ì¬ë£Œ ì†ì§ˆ**:\n",
      "   - ê°ì, ë‹¹ê·¼, ì–‘íŒŒëŠ” ê»ì§ˆì„ ë²—ê¸°ê³  ë¨¹ê¸° ì¢‹ì€ í¬ê¸°ë¡œ ê¹ë‘‘ì°ê¸°í•©ë‹ˆë‹¤.\n",
      "   - ê³ ê¸°ëŠ” í•œì… í¬ê¸°ë¡œ ì°ì–´ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¬ë£Œ ë³¶ê¸°**:\n",
      "   - ëƒ„ë¹„ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ì¤‘ë¶ˆë¡œ ê°€ì—´í•©ë‹ˆë‹¤.\n",
      "   - ê³ ê¸°ë¥¼ ë¨¼ì € ë„£ê³  ê²‰ë©´ì´ ìµì„ ë•Œê¹Œì§€ ë³¶ìŠµë‹ˆë‹¤.\n",
      "   - ê³ ê¸°ê°€ ìµìœ¼ë©´ ê°ì, ë‹¹ê·¼, ì–‘íŒŒë¥¼ ë„£ê³  í•¨ê»˜ ë³¶ì•„ì¤ë‹ˆë‹¤. (ì±„ì†Œê°€ ì‚´ì§ íˆ¬ëª…í•´ì§ˆ ë•Œê¹Œì§€)\n",
      "\n",
      "3. **ë¬¼ ë„£ê¸°**:\n",
      "   - ë³¶ì€ ì¬ë£Œì— ë¬¼ì„ ë¶“ê³  ë“ì…ë‹ˆë‹¤. ë¬¼ì˜ ì–‘ì€ ì¹´ë ˆ ê°€ë£¨ í¬ì¥ì§€ì— ì íŒ ëŒ€ë¡œ ì¡°ì ˆí•˜ì„¸ìš”.\n",
      "   - ì„¼ ë¶ˆì—ì„œ ë“ì´ë‹¤ê°€ ë“ê¸° ì‹œì‘í•˜ë©´ ì¤‘ë¶ˆë¡œ ì¤„ì´ê³  ê°ìê°€ ìµì„ ë•Œê¹Œì§€ ì•½ 10~15ë¶„ ì •ë„ ë“ì…ë‹ˆë‹¤.\n",
      "\n",
      "4. **ì¹´ë ˆ ê°€ë£¨ ë„£ê¸°**:\n",
      "   - ê°ìê°€ ìµìœ¼ë©´ ë¶ˆì„ ì•½í•˜ê²Œ ì¤„ì´ê³  ì¹´ë ˆ ê°€ë£¨ë¥¼ ë„£ìŠµë‹ˆë‹¤.\n",
      "   - ì¹´ë ˆ ê°€ë£¨ê°€ ë­‰ì¹˜ì§€ ì•Šë„ë¡ ì˜ ì €ì–´ê°€ë©° ì„ì–´ì¤ë‹ˆë‹¤.\n",
      "\n",
      "5. **ë§ˆë¬´ë¦¬**:\n",
      "   - ì¹´ë ˆê°€ ê±¸ì­‰í•´ì§ˆ ë•Œê¹Œì§€ ì•½ 5ë¶„ ì •ë„ ë” ë“ì…ë‹ˆë‹¤.\n",
      "   - ê°„ì„ ë³´ê³  ë¶€ì¡±í•œ ê²½ìš° ì†Œê¸ˆì´ë‚˜ í›„ì¶”ë¡œ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ì™„ì„±**:\n",
      "   - ë”°ëœ»í•œ ë°¥ ìœ„ì— ì¹´ë ˆë¥¼ ì–¹ì–´ ë‚´ë†“ìŠµë‹ˆë‹¤. ê¸°í˜¸ì— ë”°ë¼ ê¹€ì¹˜, í”¼í´, ê³„ë€í›„ë¼ì´ ë“±ì„ ê³ë“¤ì—¬ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### íŒ:\n",
      "- ë” í’ë¯¸ë¥¼ ì›í•œë‹¤ë©´ ì‚¬ê³¼, íŒŒì¸ì• í”Œ, ë²„ì„¯ ë“±ì„ ì¶”ê°€í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "- ë§¤ìš´ë§›ì„ ì¢‹ì•„í•œë‹¤ë©´ ê³ ì¶§ê°€ë£¨ë‚˜ ì²­ì–‘ê³ ì¶”ë¥¼ ì•½ê°„ ë„£ì–´ë³´ì„¸ìš”.\n",
      "- ì¹´ë ˆëŠ” í•˜ë£¨ ì •ë„ ìˆ™ì„±ì‹œí‚¤ë©´ ë§›ì´ ë” ê¹Šì–´ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "ë§›ìˆê²Œ ë“œì„¸ìš”! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# LCEL (LangChain Expression Language)\n",
    "# ì—°ì‡„ì ìœ¼ë¡œ ì—°ê²°í•˜ê³  ì‹¶ì€ ê²½ìš°\n",
    "# Prompt template ì„ ì±„ìš°ê³ , ê·¸ ê²°ê³¼ë¥¼ Chat modelì— ì œê³µí•œ í›„ ê·¸ ê²°ê³¼ë¥¼ Python ê°ì²´ë¡œ ë³€í™˜\n",
    "\n",
    "# promptì™€ model ì—°ê²°\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ë¦¬ì˜ ë ˆì‹œí”¼ë¥¼ ìƒê°í•´ ì£¼ì„¸ìš”.\"),\n",
    "        (\"human\", \"{dish}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_version=\"2025-04-01-preview\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "ai_message = chain.invoke({\"dish\": \"ì¹´ë ˆ\"})\n",
    "print(ai_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrOutputParserë¥¼ ì—°ê²°ì— ì¶”ê°€\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
